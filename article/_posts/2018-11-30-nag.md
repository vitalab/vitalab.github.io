---
layout: review
title:  "NAG: Network for Adversary Generation"
tags:   deep-learning CNN adversarial
author: Frédéric Branchaud-Charron
pdf:   "http://openaccess.thecvf.com/content_cvpr_2018/papers/Mopuri_NAG_Network_for_CVPR_2018_paper.pdf"
cite:
  authors: "Konda Reddy Mopuri, Utkarsh Ojha, Utsav Garg and R. Venkatesh Babu"
  title:   "NAG: Network for Adversary Generation"
  venue:   "CVPR 2018"
---

The proposed method creates a universal adversarial noise generator. The goal is to generate noise that will fool most classifiers.

![](/article/images/nag/fig1.png)

### Methodology
- Select a model $f$ (Resnet, VGG, etc).
- Get the prediction for an image $$x$$.
- Generate a noise matrix $$\delta$$.
- Get the prediction for an augmented image $$x + \delta$$.

### Losses
- Fooling loss : $$L_{f} = - log(1 - f(x + \delta)_{c})$$ where $$c = argmax_l f(x)$$.
- Diversity loss done inside a batch of size $$B$$ and at a layer $$i$$ : $$L_{d} = - \sum_{n=1}^{B} d(f^i(x_n + \delta_n), f^i(x_n + \delta_{n'}))$$ where $$n' \neq n$$ and is choose randomly. This loss encourage diversity by comparing feature maps inside the classifier.


### Results

![](/article/images/nag/table1.png)
