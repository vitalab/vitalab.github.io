---
layout: review
title:  "Scale-Aware Face Detection"
tags:   deep-learning CNN face-detection
author: Cl√©ment Zotti
pdf:   "https://arxiv.org/pdf/1706.09876.pdf"

cite:

  authors: "H.Zekun,L.Yu, Q.Hongwei, Y.Junjie, L.Xiu, H.Xiaolin"
  title:   "Scale-Aware Face Detection"
  venue:   "CVPR 2017"
---

This paper addresses a face detection problem and test their model on three face detection datasets, Face Detection Data Set and Benchmark ([FDDB](http://vis-www.cs.umass.edu/fddb/){:target="_blank"}), Multi-Attribute Labelled Faces ([MALF](http://www.cbsr.ia.ac.cn/faceevaluation/){:target="_blank"}) and Face Detection, Pose Estimation and Landmark Localization in the Wild ([AFW](http://www.ics.uci.edu/~xzhu/face/){:target="_blank"}).


## Models

They split the problem in two smaller ones. They use a network to detect the scale of faces in the image and another one to place bounding box on these faces.

### Scale Proposal Network (SPN)

First, they use a CNN model (SPN) to predict an histogram of scales of faces in the image, as shown in Fig.3.

![](/article/images/safd/spn.png)

They refine the prediction of the SPN by smoothing it with a moving average and use the non max supression algorithm to have fewer scales as shown in Fig.4.

<div align="middle">
     <img src="/article/images/safd/spn_refined.png">
</div>

### Region Proposal Network (RPN)

With the scale proposals produced by the SPN, they rescale the image given the scaling histogram and predict the boundingbox face for all the rescaled images with the Single Scale RPN as in Fig.2.

![](/article/images/safd/safd_pipeline.png){:align="middle"}

They use Faster r-cnn as their RPN method ([paper](https://arxiv.org/abs/1506.01497), [code](https://github.com/ShaoqingRen/faster_rcnn)). The inner network for these two models is made from [GoogleNet](https://arxiv.org/abs/1409.4842).

## Training

They generate the bounding box from facial landmarks to avoid the noise added when doing manual bounding box annotation. These landmarks are left eye center, right eye center, nose, left mouth corner and right mouth corner. Each bounding box generated are square.

For the scaling vector used in the SPN they use a gaussian function centered on the ground truth face size.

## Results

They report SOTA results on the three datasets with a **mean recall** of **88.15%** and an **average precision** of **98.77%**.
