---
layout: review
title:  "Fast R-CNN"
tags:   deep-learning CNN localization 
author: Pierre-Marc Jodoin 
pdf:   "https://arxiv.org/pdf/1504.08083.pdf"
cite:
  authors: "R.Girshick"
  title:   "https://arxiv.org/pdf/1504.08083.pdf"
  venue:   "International Conference on Computer Vision ({ICCV})"
---

This is an effort to improve [R-CNN]({{ site.baseurl }}{% link deep-learning/_posts/2017-04-18-rcnn.md %}).  Instead of feeding prospective bounding boxes to a CNN+SVM, the input image is fed to a VGG16 net.  At the **conv5** layer, each bounding box is used iteratively to crop the feature maps, followed by an **ROI Pooling** layer in order to resize the croped feature maps.  This is followed by the usual **FC layers + softmax**.  A bounding box regressor is also used to repositioned the bounding boxes.

<div align="middle">
  <img src="/deep-learning/images/fastrcnn/sc01.jpg" width="500">
</div>

<br>
While results are slighly better than R-CNN on VOC 2017/10/12, Fast R-CNN is much faster both at train time and at test time.
 
<div align="middle">
  <img src="/deep-learning/images/fastrcnn/sc02.jpg" width="600">
</div>


## Other stuff

[Code can be found here](https://github.com/rbgirshick/fast-rcnn)

Warning! code no longer maintained!
