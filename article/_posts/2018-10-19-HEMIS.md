---
layout: review
title: "HeMIS: Hetero-Modal Image Segmentation"
tags: deep-learning CNN brain segmentation
author: "Philippe Poulin"
cite:
    authors: "Havaei, M., Guizard, N., Chapados, N. and Bengio, Y."
    title:   "HeMIS: Hetero-Modal Image Segmentation"
    venue:   "MICCAI2016"
pdf: "https://arxiv.org/pdf/1607.05194.pdf"
---



## Summary

Problem: How to do image segmentation when multiple modalities might be available or missing?

Solution: Learn an embedding that maps each modality into a latent vector space, then use statistics in this space as input for a segmentation model.

NOTE: To keep the original resolution, there is no downsampling (they use zero-padding and a stride of 1).

> ![](/article/images/hemis/figure1.jpg)


## Training

During training, input modalities are dropped randomly using curriculum learning (start with all modalities, then gradually increase the "dropping" probability).

The model is trained end-to-end.

## Experiments

**Datasets:** 
- BRATS 2013/2015 (Brain tumors)
- MSGC/RRMS (Multiple sclerosis)

> ![](/article/images/hemis/figure3.jpg)

