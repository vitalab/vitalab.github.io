---
layout: review
title: "Learning Structured Output Representation using Deep Conditional Generative Models"
tags: deep-learning VAE segmentation 
author: "Pierre-Marc Jodoin"
cite:
    authors: "K Sohn, H Lee, X Yan."
    title:   "Learning how to Active Learn: A Deep Reinforcement Learning Approach"
    venue:   "NeurIPS 2015"
pdf: "https://papers.nips.cc/paper/5775-learning-structured-output-representation-using-deep-conditional-generative-models"
---


<center><img src="/article/images/CVAE/sc007.jpg" width="700"></center>

## Summary

Sohn et al. propose two different (but very similar) conditional VAE which they call CVAE and Gaussian stochastic NN (GSNN).  Their goal is to make structured prediction from corrupted input data.  Their overall model is illustrated in the previous image. 

## Proposed method

The CVAE model is a modification of the VAE whose objective is the well-known variational lower bound

<center><img src="/article/images/CVAE/sc000.jpg" width="500"></center>

Here, $$q_\phi(z\vert x)$$ is usually a neural network predicting a Gaussian distribution depending on $$x$$ and $$p_{\theta}(z)$$ is a prior on the latent code z, usually a zero-centered Gaussian.

For the CVAE, the aim is to generate an output $$y$$ (could be an image or a segmentation as will be shown in the results section) conditioned on $$z$$ and $$x$$ : $$p_{\theta}(y\vert x,z)$$.  The objective changes to the following conditional log-likelihood:

<center><img src="/article/images/CVAE/sc001.jpg" width="500"></center>

where $$z^l=g_{\phi}(x,y,\epsilon), \epsilon \sim N(0,1)$$


Overall, the CVAE consists of three networks : the recongition network $$q_{\psi}(z\vert x,y)$$, the prior network $$p_\theta(z\vert x)$$ and the generation network $$p_\theta(y\vert x,z)$$.  Interestingly, their implementation can be seen as a recurrent model.

The authors mention the existence of a gap between training and testing of the CVAE.  Specifically, at testing time, $$z$$ is drawn from the prior $$p_\theta(z\vert x)$$, but at training time, the recognition network $$q_{\psi}(z\vert x,y)$$ is used. To make prediction during training and testing the same, they set $$q_\psi(z\vert x,y)=q\theta (z\vert x)$$. This resulted into the following objective 

<center><img src="/article/images/CVAE/sc002.jpg" width="500"></center>


This model is called GSNN. Finally, the objectives of both models are combined in a weighted sum.

<center><img src="/article/images/CVAE/sc004.jpg" width="300"></center>



## Results

Segmentation results on corrupted input data are quite convincing.

<center><img src="/article/images/CVAE/sc005.jpg" width="700"></center>

<center><img src="/article/images/CVAE/sc006.jpg" width="700"></center>

