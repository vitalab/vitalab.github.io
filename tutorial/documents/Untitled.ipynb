{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "1e42ca46-e60f-4692-afac-8cd9516cc85c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting numpy\n",
      "  Using cached numpy-2.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (62 kB)\n",
      "Collecting Cython\n",
      "  Using cached Cython-3.0.11-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.2 kB)\n",
      "Collecting scipy\n",
      "  Using cached scipy-1.14.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (60 kB)\n",
      "Collecting torch\n",
      "  Using cached torch-2.5.1-cp310-cp310-manylinux1_x86_64.whl.metadata (28 kB)\n",
      "Collecting matplotlib\n",
      "  Using cached matplotlib-3.9.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\n",
      "Collecting dipy\n",
      "  Using cached dipy-1.9.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.0 kB)\n",
      "Collecting torchvision\n",
      "  Using cached torchvision-0.20.1-cp310-cp310-manylinux1_x86_64.whl.metadata (6.1 kB)\n",
      "Collecting lightning\n",
      "  Using cached lightning-2.4.0-py3-none-any.whl.metadata (38 kB)\n",
      "Collecting Pillow\n",
      "  Using cached pillow-11.0.0-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (9.1 kB)\n",
      "Collecting scikit-image\n",
      "  Using cached scikit_image-0.24.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (14 kB)\n",
      "Collecting tqdm\n",
      "  Using cached tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n",
      "Collecting torchio\n",
      "  Using cached torchio-0.20.3-py3-none-any.whl.metadata (49 kB)\n",
      "Collecting filelock (from torch)\n",
      "  Using cached filelock-3.16.1-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting typing-extensions>=4.8.0 (from torch)\n",
      "  Using cached typing_extensions-4.12.2-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting networkx (from torch)\n",
      "  Using cached networkx-3.4.2-py3-none-any.whl.metadata (6.3 kB)\n",
      "Collecting jinja2 (from torch)\n",
      "  Using cached jinja2-3.1.4-py3-none-any.whl.metadata (2.6 kB)\n",
      "Collecting fsspec (from torch)\n",
      "  Using cached fsspec-2024.10.0-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch)\n",
      "  Using cached nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch)\n",
      "  Using cached nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch)\n",
      "  Using cached nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch)\n",
      "  Using cached nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch)\n",
      "  Using cached nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch)\n",
      "  Using cached nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-curand-cu12==10.3.5.147 (from torch)\n",
      "  Using cached nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch)\n",
      "  Using cached nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch)\n",
      "  Using cached nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-nccl-cu12==2.21.5 (from torch)\n",
      "  Using cached nvidia_nccl_cu12-2.21.5-py3-none-manylinux2014_x86_64.whl.metadata (1.8 kB)\n",
      "Collecting nvidia-nvtx-cu12==12.4.127 (from torch)\n",
      "  Using cached nvidia_nvtx_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch)\n",
      "  Using cached nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting triton==3.1.0 (from torch)\n",
      "  Using cached triton-3.1.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.3 kB)\n",
      "Collecting sympy==1.13.1 (from torch)\n",
      "  Using cached sympy-1.13.1-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting mpmath<1.4,>=1.1.0 (from sympy==1.13.1->torch)\n",
      "  Using cached mpmath-1.3.0-py3-none-any.whl.metadata (8.6 kB)\n",
      "Collecting contourpy>=1.0.1 (from matplotlib)\n",
      "  Using cached contourpy-1.3.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.4 kB)\n",
      "Collecting cycler>=0.10 (from matplotlib)\n",
      "  Using cached cycler-0.12.1-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting fonttools>=4.22.0 (from matplotlib)\n",
      "  Using cached fonttools-4.55.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (165 kB)\n",
      "Collecting kiwisolver>=1.3.1 (from matplotlib)\n",
      "  Using cached kiwisolver-1.4.7-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl.metadata (6.3 kB)\n",
      "Collecting packaging>=20.0 (from matplotlib)\n",
      "  Using cached packaging-24.2-py3-none-any.whl.metadata (3.2 kB)\n",
      "Collecting pyparsing>=2.3.1 (from matplotlib)\n",
      "  Using cached pyparsing-3.2.0-py3-none-any.whl.metadata (5.0 kB)\n",
      "Collecting python-dateutil>=2.7 (from matplotlib)\n",
      "  Using cached python_dateutil-2.9.0.post0-py2.py3-none-any.whl.metadata (8.4 kB)\n",
      "Collecting nibabel>=3.0.0 (from dipy)\n",
      "  Using cached nibabel-5.3.2-py3-none-any.whl.metadata (9.1 kB)\n",
      "Collecting h5py>=3.1.0 (from dipy)\n",
      "  Using cached h5py-3.12.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.5 kB)\n",
      "Collecting trx-python>=0.2.9 (from dipy)\n",
      "  Using cached trx_python-0.3-py3-none-any.whl.metadata (2.7 kB)\n",
      "Collecting PyYAML<8.0,>=5.4 (from lightning)\n",
      "  Using cached PyYAML-6.0.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.1 kB)\n",
      "Collecting lightning-utilities<2.0,>=0.10.0 (from lightning)\n",
      "  Using cached lightning_utilities-0.11.9-py3-none-any.whl.metadata (5.2 kB)\n",
      "Collecting torchmetrics<3.0,>=0.7.0 (from lightning)\n",
      "  Using cached torchmetrics-1.6.0-py3-none-any.whl.metadata (20 kB)\n",
      "Collecting pytorch-lightning (from lightning)\n",
      "  Using cached pytorch_lightning-2.4.0-py3-none-any.whl.metadata (21 kB)\n",
      "Collecting imageio>=2.33 (from scikit-image)\n",
      "  Using cached imageio-2.36.1-py3-none-any.whl.metadata (5.2 kB)\n",
      "Collecting tifffile>=2022.8.12 (from scikit-image)\n",
      "  Using cached tifffile-2024.9.20-py3-none-any.whl.metadata (32 kB)\n",
      "Collecting lazy-loader>=0.4 (from scikit-image)\n",
      "  Using cached lazy_loader-0.4-py3-none-any.whl.metadata (7.6 kB)\n",
      "Collecting deprecated>=1.2 (from torchio)\n",
      "  Using cached Deprecated-1.2.15-py2.py3-none-any.whl.metadata (5.5 kB)\n",
      "Collecting humanize>=0.1 (from torchio)\n",
      "  Using cached humanize-4.11.0-py3-none-any.whl.metadata (7.8 kB)\n",
      "Collecting rich>=10 (from torchio)\n",
      "  Using cached rich-13.9.4-py3-none-any.whl.metadata (18 kB)\n",
      "Collecting simpleitk!=2.0.*,!=2.1.1.1,>=1.3 (from torchio)\n",
      "  Using cached SimpleITK-2.4.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.9 kB)\n",
      "Collecting typer>=0.1 (from torchio)\n",
      "  Using cached typer-0.15.1-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting wrapt<2,>=1.10 (from deprecated>=1.2->torchio)\n",
      "  Using cached wrapt-1.17.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.4 kB)\n",
      "Collecting aiohttp!=4.0.0a0,!=4.0.0a1 (from fsspec[http]<2026.0,>=2022.5.0->lightning)\n",
      "  Using cached aiohttp-3.11.10-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.7 kB)\n",
      "Collecting setuptools (from lightning-utilities<2.0,>=0.10.0->lightning)\n",
      "  Using cached setuptools-75.6.0-py3-none-any.whl.metadata (6.7 kB)\n",
      "Collecting importlib-resources>=5.12 (from nibabel>=3.0.0->dipy)\n",
      "  Using cached importlib_resources-6.4.5-py3-none-any.whl.metadata (4.0 kB)\n",
      "Collecting six>=1.5 (from python-dateutil>=2.7->matplotlib)\n",
      "  Using cached six-1.17.0-py2.py3-none-any.whl.metadata (1.7 kB)\n",
      "Collecting markdown-it-py>=2.2.0 (from rich>=10->torchio)\n",
      "  Using cached markdown_it_py-3.0.0-py3-none-any.whl.metadata (6.9 kB)\n",
      "Collecting pygments<3.0.0,>=2.13.0 (from rich>=10->torchio)\n",
      "  Using cached pygments-2.18.0-py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting setuptools-scm (from trx-python>=0.2.9->dipy)\n",
      "  Using cached setuptools_scm-8.1.0-py3-none-any.whl.metadata (6.6 kB)\n",
      "Collecting deepdiff (from trx-python>=0.2.9->dipy)\n",
      "  Using cached deepdiff-8.0.1-py3-none-any.whl.metadata (8.5 kB)\n",
      "Collecting click>=8.0.0 (from typer>=0.1->torchio)\n",
      "  Using cached click-8.1.7-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting shellingham>=1.3.0 (from typer>=0.1->torchio)\n",
      "  Using cached shellingham-1.5.4-py2.py3-none-any.whl.metadata (3.5 kB)\n",
      "Collecting MarkupSafe>=2.0 (from jinja2->torch)\n",
      "  Using cached MarkupSafe-3.0.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.0 kB)\n",
      "Collecting aiohappyeyeballs>=2.3.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning)\n",
      "  Using cached aiohappyeyeballs-2.4.4-py3-none-any.whl.metadata (6.1 kB)\n",
      "Collecting aiosignal>=1.1.2 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning)\n",
      "  Using cached aiosignal-1.3.1-py3-none-any.whl.metadata (4.0 kB)\n",
      "Collecting async-timeout<6.0,>=4.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning)\n",
      "  Using cached async_timeout-5.0.1-py3-none-any.whl.metadata (5.1 kB)\n",
      "Collecting attrs>=17.3.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning)\n",
      "  Using cached attrs-24.2.0-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting frozenlist>=1.1.1 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning)\n",
      "  Using cached frozenlist-1.5.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (13 kB)\n",
      "Collecting multidict<7.0,>=4.5 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning)\n",
      "  Using cached multidict-6.1.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.0 kB)\n",
      "Collecting propcache>=0.2.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning)\n",
      "  Using cached propcache-0.2.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.2 kB)\n",
      "Collecting yarl<2.0,>=1.17.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning)\n",
      "  Using cached yarl-1.18.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (69 kB)\n",
      "Collecting mdurl~=0.1 (from markdown-it-py>=2.2.0->rich>=10->torchio)\n",
      "  Using cached mdurl-0.1.2-py3-none-any.whl.metadata (1.6 kB)\n",
      "Collecting orderly-set==5.2.2 (from deepdiff->trx-python>=0.2.9->dipy)\n",
      "  Using cached orderly_set-5.2.2-py3-none-any.whl.metadata (6.3 kB)\n",
      "Collecting tomli>=1 (from setuptools-scm->trx-python>=0.2.9->dipy)\n",
      "  Using cached tomli-2.2.1-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting idna>=2.0 (from yarl<2.0,>=1.17.0->aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning)\n",
      "  Using cached idna-3.10-py3-none-any.whl.metadata (10 kB)\n",
      "Using cached numpy-2.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (16.4 MB)\n",
      "Using cached Cython-3.0.11-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.6 MB)\n",
      "Using cached scipy-1.14.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (41.2 MB)\n",
      "Using cached torch-2.5.1-cp310-cp310-manylinux1_x86_64.whl (906.4 MB)\n",
      "Using cached nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
      "Using cached nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
      "Using cached nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
      "Using cached nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
      "Using cached nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
      "Using cached nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
      "Using cached nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
      "Using cached nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
      "Using cached nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
      "Using cached nvidia_nccl_cu12-2.21.5-py3-none-manylinux2014_x86_64.whl (188.7 MB)\n",
      "Using cached nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
      "Using cached nvidia_nvtx_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (99 kB)\n",
      "Using cached sympy-1.13.1-py3-none-any.whl (6.2 MB)\n",
      "Using cached triton-3.1.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (209.5 MB)\n",
      "Using cached matplotlib-3.9.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (8.3 MB)\n",
      "Using cached dipy-1.9.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (9.0 MB)\n",
      "Using cached torchvision-0.20.1-cp310-cp310-manylinux1_x86_64.whl (7.2 MB)\n",
      "Using cached lightning-2.4.0-py3-none-any.whl (810 kB)\n",
      "Using cached pillow-11.0.0-cp310-cp310-manylinux_2_28_x86_64.whl (4.4 MB)\n",
      "Using cached scikit_image-0.24.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (14.9 MB)\n",
      "Using cached tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
      "Using cached torchio-0.20.3-py3-none-any.whl (175 kB)\n",
      "Using cached contourpy-1.3.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (324 kB)\n",
      "Using cached cycler-0.12.1-py3-none-any.whl (8.3 kB)\n",
      "Using cached Deprecated-1.2.15-py2.py3-none-any.whl (9.9 kB)\n",
      "Using cached fonttools-4.55.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.6 MB)\n",
      "Using cached fsspec-2024.10.0-py3-none-any.whl (179 kB)\n",
      "Using cached h5py-3.12.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.3 MB)\n",
      "Using cached humanize-4.11.0-py3-none-any.whl (128 kB)\n",
      "Using cached imageio-2.36.1-py3-none-any.whl (315 kB)\n",
      "Using cached kiwisolver-1.4.7-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.6 MB)\n",
      "Using cached lazy_loader-0.4-py3-none-any.whl (12 kB)\n",
      "Using cached lightning_utilities-0.11.9-py3-none-any.whl (28 kB)\n",
      "Using cached networkx-3.4.2-py3-none-any.whl (1.7 MB)\n",
      "Using cached nibabel-5.3.2-py3-none-any.whl (3.3 MB)\n",
      "Using cached packaging-24.2-py3-none-any.whl (65 kB)\n",
      "Using cached pyparsing-3.2.0-py3-none-any.whl (106 kB)\n",
      "Using cached python_dateutil-2.9.0.post0-py2.py3-none-any.whl (229 kB)\n",
      "Using cached PyYAML-6.0.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (751 kB)\n",
      "Using cached rich-13.9.4-py3-none-any.whl (242 kB)\n",
      "Using cached SimpleITK-2.4.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (52.4 MB)\n",
      "Using cached tifffile-2024.9.20-py3-none-any.whl (228 kB)\n",
      "Using cached torchmetrics-1.6.0-py3-none-any.whl (926 kB)\n",
      "Using cached trx_python-0.3-py3-none-any.whl (45 kB)\n",
      "Using cached typer-0.15.1-py3-none-any.whl (44 kB)\n",
      "Using cached typing_extensions-4.12.2-py3-none-any.whl (37 kB)\n",
      "Using cached filelock-3.16.1-py3-none-any.whl (16 kB)\n",
      "Using cached jinja2-3.1.4-py3-none-any.whl (133 kB)\n",
      "Using cached pytorch_lightning-2.4.0-py3-none-any.whl (815 kB)\n",
      "Using cached aiohttp-3.11.10-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.6 MB)\n",
      "Using cached click-8.1.7-py3-none-any.whl (97 kB)\n",
      "Using cached importlib_resources-6.4.5-py3-none-any.whl (36 kB)\n",
      "Using cached markdown_it_py-3.0.0-py3-none-any.whl (87 kB)\n",
      "Using cached MarkupSafe-3.0.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (20 kB)\n",
      "Using cached mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "Using cached pygments-2.18.0-py3-none-any.whl (1.2 MB)\n",
      "Using cached shellingham-1.5.4-py2.py3-none-any.whl (9.8 kB)\n",
      "Using cached six-1.17.0-py2.py3-none-any.whl (11 kB)\n",
      "Using cached wrapt-1.17.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (82 kB)\n",
      "Using cached deepdiff-8.0.1-py3-none-any.whl (82 kB)\n",
      "Using cached orderly_set-5.2.2-py3-none-any.whl (11 kB)\n",
      "Using cached setuptools-75.6.0-py3-none-any.whl (1.2 MB)\n",
      "Using cached setuptools_scm-8.1.0-py3-none-any.whl (43 kB)\n",
      "Using cached aiohappyeyeballs-2.4.4-py3-none-any.whl (14 kB)\n",
      "Using cached aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
      "Using cached async_timeout-5.0.1-py3-none-any.whl (6.2 kB)\n",
      "Using cached attrs-24.2.0-py3-none-any.whl (63 kB)\n",
      "Using cached frozenlist-1.5.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (241 kB)\n",
      "Using cached mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
      "Using cached multidict-6.1.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (124 kB)\n",
      "Using cached propcache-0.2.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (205 kB)\n",
      "Using cached tomli-2.2.1-py3-none-any.whl (14 kB)\n",
      "Using cached yarl-1.18.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (319 kB)\n",
      "Using cached idna-3.10-py3-none-any.whl (70 kB)\n",
      "Installing collected packages: simpleitk, mpmath, wrapt, typing-extensions, tqdm, tomli, sympy, six, shellingham, setuptools, PyYAML, pyparsing, pygments, propcache, Pillow, packaging, orderly-set, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, numpy, networkx, mdurl, MarkupSafe, kiwisolver, importlib-resources, idna, humanize, fsspec, frozenlist, fonttools, filelock, Cython, cycler, click, attrs, async-timeout, aiohappyeyeballs, triton, tifffile, setuptools-scm, scipy, python-dateutil, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nibabel, multidict, markdown-it-py, lightning-utilities, lazy-loader, jinja2, imageio, h5py, deprecated, deepdiff, contourpy, aiosignal, yarl, trx-python, scikit-image, rich, nvidia-cusolver-cu12, matplotlib, typer, torch, dipy, aiohttp, torchvision, torchmetrics, torchio, pytorch-lightning, lightning\n",
      "  Attempting uninstall: simpleitk\n",
      "    Found existing installation: SimpleITK 2.4.0\n",
      "    Uninstalling SimpleITK-2.4.0:\n",
      "      Successfully uninstalled SimpleITK-2.4.0\n",
      "  Attempting uninstall: mpmath\n",
      "    Found existing installation: mpmath 1.3.0\n",
      "    Uninstalling mpmath-1.3.0:\n",
      "      Successfully uninstalled mpmath-1.3.0\n",
      "  Attempting uninstall: wrapt\n",
      "    Found existing installation: wrapt 1.17.0\n",
      "    Uninstalling wrapt-1.17.0:\n",
      "      Successfully uninstalled wrapt-1.17.0\n",
      "  Attempting uninstall: typing-extensions\n",
      "    Found existing installation: typing_extensions 4.12.2\n",
      "    Uninstalling typing_extensions-4.12.2:\n",
      "      Successfully uninstalled typing_extensions-4.12.2\n",
      "  Attempting uninstall: tqdm\n",
      "    Found existing installation: tqdm 4.67.1\n",
      "    Uninstalling tqdm-4.67.1:\n",
      "      Successfully uninstalled tqdm-4.67.1\n",
      "  Attempting uninstall: tomli\n",
      "    Found existing installation: tomli 2.2.1\n",
      "    Uninstalling tomli-2.2.1:\n",
      "      Successfully uninstalled tomli-2.2.1\n",
      "  Attempting uninstall: sympy\n",
      "    Found existing installation: sympy 1.13.1\n",
      "    Uninstalling sympy-1.13.1:\n",
      "      Successfully uninstalled sympy-1.13.1\n",
      "  Attempting uninstall: six\n",
      "    Found existing installation: six 1.17.0\n",
      "    Uninstalling six-1.17.0:\n",
      "      Successfully uninstalled six-1.17.0\n",
      "  Attempting uninstall: shellingham\n",
      "    Found existing installation: shellingham 1.5.4\n",
      "    Uninstalling shellingham-1.5.4:\n",
      "      Successfully uninstalled shellingham-1.5.4\n",
      "  Attempting uninstall: setuptools\n",
      "    Found existing installation: setuptools 75.6.0\n",
      "    Uninstalling setuptools-75.6.0:\n",
      "      Successfully uninstalled setuptools-75.6.0\n",
      "  Attempting uninstall: PyYAML\n",
      "    Found existing installation: PyYAML 6.0.2\n",
      "    Uninstalling PyYAML-6.0.2:\n",
      "      Successfully uninstalled PyYAML-6.0.2\n",
      "  Attempting uninstall: pyparsing\n",
      "    Found existing installation: pyparsing 3.2.0\n",
      "    Uninstalling pyparsing-3.2.0:\n",
      "      Successfully uninstalled pyparsing-3.2.0\n",
      "  Attempting uninstall: pygments\n",
      "    Found existing installation: Pygments 2.18.0\n",
      "    Uninstalling Pygments-2.18.0:\n",
      "      Successfully uninstalled Pygments-2.18.0\n",
      "  Attempting uninstall: propcache\n",
      "    Found existing installation: propcache 0.2.1\n",
      "    Uninstalling propcache-0.2.1:\n",
      "      Successfully uninstalled propcache-0.2.1\n",
      "  Attempting uninstall: Pillow\n",
      "    Found existing installation: pillow 11.0.0\n",
      "    Uninstalling pillow-11.0.0:\n",
      "      Successfully uninstalled pillow-11.0.0\n",
      "  Attempting uninstall: packaging\n",
      "    Found existing installation: packaging 24.2\n",
      "    Uninstalling packaging-24.2:\n",
      "      Successfully uninstalled packaging-24.2\n",
      "  Attempting uninstall: orderly-set\n",
      "    Found existing installation: orderly-set 5.2.2\n",
      "    Uninstalling orderly-set-5.2.2:\n",
      "      Successfully uninstalled orderly-set-5.2.2\n",
      "  Attempting uninstall: nvidia-nvtx-cu12\n",
      "    Found existing installation: nvidia-nvtx-cu12 12.4.127\n",
      "    Uninstalling nvidia-nvtx-cu12-12.4.127:\n",
      "      Successfully uninstalled nvidia-nvtx-cu12-12.4.127\n",
      "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
      "    Found existing installation: nvidia-nvjitlink-cu12 12.4.127\n",
      "    Uninstalling nvidia-nvjitlink-cu12-12.4.127:\n",
      "      Successfully uninstalled nvidia-nvjitlink-cu12-12.4.127\n",
      "  Attempting uninstall: nvidia-nccl-cu12\n",
      "    Found existing installation: nvidia-nccl-cu12 2.21.5\n",
      "    Uninstalling nvidia-nccl-cu12-2.21.5:\n",
      "      Successfully uninstalled nvidia-nccl-cu12-2.21.5\n",
      "  Attempting uninstall: nvidia-curand-cu12\n",
      "    Found existing installation: nvidia-curand-cu12 10.3.5.147\n",
      "    Uninstalling nvidia-curand-cu12-10.3.5.147:\n",
      "      Successfully uninstalled nvidia-curand-cu12-10.3.5.147\n",
      "  Attempting uninstall: nvidia-cufft-cu12\n",
      "    Found existing installation: nvidia-cufft-cu12 11.2.1.3\n",
      "    Uninstalling nvidia-cufft-cu12-11.2.1.3:\n",
      "      Successfully uninstalled nvidia-cufft-cu12-11.2.1.3\n",
      "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
      "    Found existing installation: nvidia-cuda-runtime-cu12 12.4.127\n",
      "    Uninstalling nvidia-cuda-runtime-cu12-12.4.127:\n",
      "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.4.127\n",
      "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
      "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.4.127\n",
      "    Uninstalling nvidia-cuda-nvrtc-cu12-12.4.127:\n",
      "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.4.127\n",
      "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
      "    Found existing installation: nvidia-cuda-cupti-cu12 12.4.127\n",
      "    Uninstalling nvidia-cuda-cupti-cu12-12.4.127:\n",
      "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.4.127\n",
      "  Attempting uninstall: nvidia-cublas-cu12\n",
      "    Found existing installation: nvidia-cublas-cu12 12.4.5.8\n",
      "    Uninstalling nvidia-cublas-cu12-12.4.5.8:\n",
      "      Successfully uninstalled nvidia-cublas-cu12-12.4.5.8\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 1.22.4\n",
      "    Uninstalling numpy-1.22.4:\n",
      "      Successfully uninstalled numpy-1.22.4\n",
      "  Attempting uninstall: networkx\n",
      "    Found existing installation: networkx 3.4.2\n",
      "    Uninstalling networkx-3.4.2:\n",
      "      Successfully uninstalled networkx-3.4.2\n",
      "  Attempting uninstall: mdurl\n",
      "    Found existing installation: mdurl 0.1.2\n",
      "    Uninstalling mdurl-0.1.2:\n",
      "      Successfully uninstalled mdurl-0.1.2\n",
      "  Attempting uninstall: MarkupSafe\n",
      "    Found existing installation: MarkupSafe 3.0.2\n",
      "    Uninstalling MarkupSafe-3.0.2:\n",
      "      Successfully uninstalled MarkupSafe-3.0.2\n",
      "  Attempting uninstall: kiwisolver\n",
      "    Found existing installation: kiwisolver 1.4.7\n",
      "    Uninstalling kiwisolver-1.4.7:\n",
      "      Successfully uninstalled kiwisolver-1.4.7\n",
      "  Attempting uninstall: importlib-resources\n",
      "    Found existing installation: importlib_resources 6.4.5\n",
      "    Uninstalling importlib_resources-6.4.5:\n",
      "      Successfully uninstalled importlib_resources-6.4.5\n",
      "  Attempting uninstall: idna\n",
      "    Found existing installation: idna 3.10\n",
      "    Uninstalling idna-3.10:\n",
      "      Successfully uninstalled idna-3.10\n",
      "  Attempting uninstall: humanize\n",
      "    Found existing installation: humanize 4.11.0\n",
      "    Uninstalling humanize-4.11.0:\n",
      "      Successfully uninstalled humanize-4.11.0\n",
      "  Attempting uninstall: fsspec\n",
      "    Found existing installation: fsspec 2024.10.0\n",
      "    Uninstalling fsspec-2024.10.0:\n",
      "      Successfully uninstalled fsspec-2024.10.0\n",
      "  Attempting uninstall: frozenlist\n",
      "    Found existing installation: frozenlist 1.5.0\n",
      "    Uninstalling frozenlist-1.5.0:\n",
      "      Successfully uninstalled frozenlist-1.5.0\n",
      "  Attempting uninstall: fonttools\n",
      "    Found existing installation: fonttools 4.55.3\n",
      "    Uninstalling fonttools-4.55.3:\n",
      "      Successfully uninstalled fonttools-4.55.3\n",
      "  Attempting uninstall: filelock\n",
      "    Found existing installation: filelock 3.16.1\n",
      "    Uninstalling filelock-3.16.1:\n",
      "      Successfully uninstalled filelock-3.16.1\n",
      "  Attempting uninstall: Cython\n",
      "    Found existing installation: Cython 3.0.11\n",
      "    Uninstalling Cython-3.0.11:\n",
      "      Successfully uninstalled Cython-3.0.11\n",
      "  Attempting uninstall: cycler\n",
      "    Found existing installation: cycler 0.12.1\n",
      "    Uninstalling cycler-0.12.1:\n",
      "      Successfully uninstalled cycler-0.12.1\n",
      "  Attempting uninstall: click\n",
      "    Found existing installation: click 8.1.7\n",
      "    Uninstalling click-8.1.7:\n",
      "      Successfully uninstalled click-8.1.7\n",
      "  Attempting uninstall: attrs\n",
      "    Found existing installation: attrs 24.2.0\n",
      "    Uninstalling attrs-24.2.0:\n",
      "      Successfully uninstalled attrs-24.2.0\n",
      "  Attempting uninstall: async-timeout\n",
      "    Found existing installation: async-timeout 5.0.1\n",
      "    Uninstalling async-timeout-5.0.1:\n",
      "      Successfully uninstalled async-timeout-5.0.1\n",
      "  Attempting uninstall: aiohappyeyeballs\n",
      "    Found existing installation: aiohappyeyeballs 2.4.4\n",
      "    Uninstalling aiohappyeyeballs-2.4.4:\n",
      "      Successfully uninstalled aiohappyeyeballs-2.4.4\n",
      "  Attempting uninstall: triton\n",
      "    Found existing installation: triton 3.1.0\n",
      "    Uninstalling triton-3.1.0:\n",
      "      Successfully uninstalled triton-3.1.0\n",
      "  Attempting uninstall: tifffile\n",
      "    Found existing installation: tifffile 2024.9.20\n",
      "    Uninstalling tifffile-2024.9.20:\n",
      "      Successfully uninstalled tifffile-2024.9.20\n",
      "  Attempting uninstall: setuptools-scm\n",
      "    Found existing installation: setuptools-scm 8.1.0\n",
      "    Uninstalling setuptools-scm-8.1.0:\n",
      "      Successfully uninstalled setuptools-scm-8.1.0\n",
      "  Attempting uninstall: scipy\n",
      "    Found existing installation: scipy 1.13.1\n",
      "    Uninstalling scipy-1.13.1:\n",
      "      Successfully uninstalled scipy-1.13.1\n",
      "  Attempting uninstall: python-dateutil\n",
      "    Found existing installation: python-dateutil 2.9.0.post0\n",
      "    Uninstalling python-dateutil-2.9.0.post0:\n",
      "      Successfully uninstalled python-dateutil-2.9.0.post0\n",
      "  Attempting uninstall: nvidia-cusparse-cu12\n",
      "    Found existing installation: nvidia-cusparse-cu12 12.3.1.170\n",
      "    Uninstalling nvidia-cusparse-cu12-12.3.1.170:\n",
      "      Successfully uninstalled nvidia-cusparse-cu12-12.3.1.170\n",
      "  Attempting uninstall: nvidia-cudnn-cu12\n",
      "    Found existing installation: nvidia-cudnn-cu12 9.1.0.70\n",
      "    Uninstalling nvidia-cudnn-cu12-9.1.0.70:\n",
      "      Successfully uninstalled nvidia-cudnn-cu12-9.1.0.70\n",
      "  Attempting uninstall: nibabel\n",
      "    Found existing installation: nibabel 5.3.2\n",
      "    Uninstalling nibabel-5.3.2:\n",
      "      Successfully uninstalled nibabel-5.3.2\n",
      "  Attempting uninstall: multidict\n",
      "    Found existing installation: multidict 6.1.0\n",
      "    Uninstalling multidict-6.1.0:\n",
      "      Successfully uninstalled multidict-6.1.0\n",
      "  Attempting uninstall: markdown-it-py\n",
      "    Found existing installation: markdown-it-py 3.0.0\n",
      "    Uninstalling markdown-it-py-3.0.0:\n",
      "      Successfully uninstalled markdown-it-py-3.0.0\n",
      "  Attempting uninstall: lightning-utilities\n",
      "    Found existing installation: lightning-utilities 0.11.9\n",
      "    Uninstalling lightning-utilities-0.11.9:\n",
      "      Successfully uninstalled lightning-utilities-0.11.9\n",
      "  Attempting uninstall: lazy-loader\n",
      "    Found existing installation: lazy_loader 0.4\n",
      "    Uninstalling lazy_loader-0.4:\n",
      "      Successfully uninstalled lazy_loader-0.4\n",
      "  Attempting uninstall: jinja2\n",
      "    Found existing installation: Jinja2 3.1.4\n",
      "    Uninstalling Jinja2-3.1.4:\n",
      "      Successfully uninstalled Jinja2-3.1.4\n",
      "  Attempting uninstall: imageio\n",
      "    Found existing installation: imageio 2.36.1\n",
      "    Uninstalling imageio-2.36.1:\n",
      "      Successfully uninstalled imageio-2.36.1\n",
      "  Attempting uninstall: h5py\n",
      "    Found existing installation: h5py 3.12.1\n",
      "    Uninstalling h5py-3.12.1:\n",
      "      Successfully uninstalled h5py-3.12.1\n",
      "  Attempting uninstall: deprecated\n",
      "    Found existing installation: Deprecated 1.2.15\n",
      "    Uninstalling Deprecated-1.2.15:\n",
      "      Successfully uninstalled Deprecated-1.2.15\n",
      "  Attempting uninstall: deepdiff\n",
      "    Found existing installation: deepdiff 8.0.1\n",
      "    Uninstalling deepdiff-8.0.1:\n",
      "      Successfully uninstalled deepdiff-8.0.1\n",
      "  Attempting uninstall: contourpy\n",
      "    Found existing installation: contourpy 1.2.1\n",
      "    Uninstalling contourpy-1.2.1:\n",
      "      Successfully uninstalled contourpy-1.2.1\n",
      "  Attempting uninstall: aiosignal\n",
      "    Found existing installation: aiosignal 1.3.1\n",
      "    Uninstalling aiosignal-1.3.1:\n",
      "      Successfully uninstalled aiosignal-1.3.1\n",
      "  Attempting uninstall: yarl\n",
      "    Found existing installation: yarl 1.18.3\n",
      "    Uninstalling yarl-1.18.3:\n",
      "      Successfully uninstalled yarl-1.18.3\n",
      "  Attempting uninstall: trx-python\n",
      "    Found existing installation: trx-python 0.3\n",
      "    Uninstalling trx-python-0.3:\n",
      "      Successfully uninstalled trx-python-0.3\n",
      "  Attempting uninstall: scikit-image\n",
      "    Found existing installation: scikit-image 0.22.0\n",
      "    Uninstalling scikit-image-0.22.0:\n",
      "      Successfully uninstalled scikit-image-0.22.0\n",
      "  Attempting uninstall: rich\n",
      "    Found existing installation: rich 13.9.4\n",
      "    Uninstalling rich-13.9.4:\n",
      "      Successfully uninstalled rich-13.9.4\n",
      "  Attempting uninstall: nvidia-cusolver-cu12\n",
      "    Found existing installation: nvidia-cusolver-cu12 11.6.1.9\n",
      "    Uninstalling nvidia-cusolver-cu12-11.6.1.9:\n",
      "      Successfully uninstalled nvidia-cusolver-cu12-11.6.1.9\n",
      "  Attempting uninstall: matplotlib\n",
      "    Found existing installation: matplotlib 3.8.4\n",
      "    Uninstalling matplotlib-3.8.4:\n",
      "      Successfully uninstalled matplotlib-3.8.4\n",
      "  Attempting uninstall: typer\n",
      "    Found existing installation: typer 0.15.1\n",
      "    Uninstalling typer-0.15.1:\n",
      "      Successfully uninstalled typer-0.15.1\n",
      "  Attempting uninstall: torch\n",
      "    Found existing installation: torch 2.5.1\n",
      "    Uninstalling torch-2.5.1:\n",
      "      Successfully uninstalled torch-2.5.1\n",
      "  Attempting uninstall: dipy\n",
      "    Found existing installation: dipy 1.9.0\n",
      "    Uninstalling dipy-1.9.0:\n",
      "      Successfully uninstalled dipy-1.9.0\n",
      "  Attempting uninstall: aiohttp\n",
      "    Found existing installation: aiohttp 3.11.10\n",
      "    Uninstalling aiohttp-3.11.10:\n",
      "      Successfully uninstalled aiohttp-3.11.10\n",
      "  Attempting uninstall: torchvision\n",
      "    Found existing installation: torchvision 0.20.1\n",
      "    Uninstalling torchvision-0.20.1:\n",
      "      Successfully uninstalled torchvision-0.20.1\n",
      "  Attempting uninstall: torchmetrics\n",
      "    Found existing installation: torchmetrics 1.6.0\n",
      "    Uninstalling torchmetrics-1.6.0:\n",
      "      Successfully uninstalled torchmetrics-1.6.0\n",
      "  Attempting uninstall: torchio\n",
      "    Found existing installation: torchio 0.20.3\n",
      "    Uninstalling torchio-0.20.3:\n",
      "      Successfully uninstalled torchio-0.20.3\n",
      "  Attempting uninstall: pytorch-lightning\n",
      "    Found existing installation: pytorch-lightning 2.4.0\n",
      "    Uninstalling pytorch-lightning-2.4.0:\n",
      "      Successfully uninstalled pytorch-lightning-2.4.0\n",
      "  Attempting uninstall: lightning\n",
      "    Found existing installation: lightning 2.4.0\n",
      "    Uninstalling lightning-2.4.0:\n",
      "      Successfully uninstalled lightning-2.4.0\n",
      "Successfully installed Cython-3.0.11 MarkupSafe-3.0.2 Pillow-11.0.0 PyYAML-6.0.2 aiohappyeyeballs-2.4.4 aiohttp-3.11.10 aiosignal-1.3.1 async-timeout-5.0.1 attrs-24.2.0 click-8.1.7 contourpy-1.3.1 cycler-0.12.1 deepdiff-8.0.1 deprecated-1.2.15 dipy-1.9.0 filelock-3.16.1 fonttools-4.55.3 frozenlist-1.5.0 fsspec-2024.10.0 h5py-3.12.1 humanize-4.11.0 idna-3.10 imageio-2.36.1 importlib-resources-6.4.5 jinja2-3.1.4 kiwisolver-1.4.7 lazy-loader-0.4 lightning-2.4.0 lightning-utilities-0.11.9 markdown-it-py-3.0.0 matplotlib-3.9.3 mdurl-0.1.2 mpmath-1.3.0 multidict-6.1.0 networkx-3.4.2 nibabel-5.3.2 numpy-2.2.0 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nccl-cu12-2.21.5 nvidia-nvjitlink-cu12-12.4.127 nvidia-nvtx-cu12-12.4.127 orderly-set-5.2.2 packaging-24.2 propcache-0.2.1 pygments-2.18.0 pyparsing-3.2.0 python-dateutil-2.9.0.post0 pytorch-lightning-2.4.0 rich-13.9.4 scikit-image-0.24.0 scipy-1.14.1 setuptools-75.6.0 setuptools-scm-8.1.0 shellingham-1.5.4 simpleitk-2.4.0 six-1.17.0 sympy-1.13.1 tifffile-2024.9.20 tomli-2.2.1 torch-2.5.1 torchio-0.20.3 torchmetrics-1.6.0 torchvision-0.20.1 tqdm-4.67.1 triton-3.1.0 trx-python-0.3 typer-0.15.1 typing-extensions-4.12.2 wrapt-1.17.0 yarl-1.18.3\n"
     ]
    }
   ],
   "source": [
    "!pip install numpy Cython scipy torch matplotlib dipy torchvision lightning Pillow scikit-image tqdm torchio --force"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1dd68098-95a8-4b67-acb1-3a672dd5e74a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import os\n",
    "\n",
    "from PIL import Image\n",
    "from torchvision.transforms import Resize, Compose, ToTensor, Normalize\n",
    "import numpy as np\n",
    "import skimage\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "424fc410-6b47-4bad-9e76-b4450e1262fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "class ReLULayer(nn.Module):\n",
    "    def __init__(self,\n",
    "                 in_size: int,\n",
    "                 out_size: int,\n",
    "                 **kwargs):\n",
    "        super().__init__()\n",
    "        self.linear = nn.Linear(in_size, out_size, bias=True)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        x = self.linear(x)\n",
    "        x = torch.relu(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self,\n",
    "                 in_size: int,\n",
    "                 out_size: int,\n",
    "                 hidden_size: int = 128,\n",
    "                 num_layers: int = 3,\n",
    "                 layer_class: nn.Module = ReLULayer,\n",
    "                 **kwargs):\n",
    "        super().__init__()\n",
    "\n",
    "        a = [layer_class(in_size, hidden_size, **kwargs)]\n",
    "        for i in range(num_layers - 1):\n",
    "            a.append(layer_class(hidden_size, hidden_size, **kwargs))\n",
    "        a.append(nn.Linear(hidden_size, out_size))\n",
    "        self.layers = nn.ModuleList(a)        \n",
    "\n",
    "    def forward(self, x: torch.Tensor):\n",
    "        for layer in self.layers:\n",
    "            x = layer(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "09159a54-0c4c-4002-8403-20fda34b3310",
   "metadata": {},
   "outputs": [],
   "source": [
    "def laplace(y, x):\n",
    "    grad = gradient(y, x)\n",
    "    return divergence(grad, x)\n",
    "\n",
    "\n",
    "def divergence(y, x):\n",
    "    div = 0.\n",
    "    for i in range(y.shape[-1]):\n",
    "        div += torch.autograd.grad(y[..., i], x, torch.ones_like(y[..., i]), create_graph=True)[0][..., i:i+1]\n",
    "    return div\n",
    "\n",
    "\n",
    "def gradient(y, x, grad_outputs=None):\n",
    "    if grad_outputs is None:\n",
    "        grad_outputs = torch.ones_like(y)\n",
    "    grad = torch.autograd.grad(y, [x], grad_outputs=grad_outputs, create_graph=True)[0]\n",
    "    return grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "8de933ea-691d-4ab3-91b0-9d27f6333d33",
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "import torchio as tio\n",
    "\n",
    "\n",
    "POINTS_PER_SAMPLE = 2048\n",
    "        \n",
    "subject = tio.datasets.T1T2()\n",
    "gt_image = torch.from_numpy(np.asarray(subject.mprage)).permute(1, 2, 3, 0)\n",
    "\n",
    "class RandomPointsDataset(Dataset):\n",
    "    def __init__(self, image: torch.Tensor, points_num: int = POINTS_PER_SAMPLE):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.device = \"cpu\"\n",
    "        self.points_num = points_num\n",
    "        self.image = image.to(self.device, dtype=torch.float32)  # (H, W, ..., C)\n",
    "        self.dim_sizes = self.image.shape[:-1]  # Size of each spatial dimension\n",
    "\n",
    "        # To help us define the input/output sizes of our network later\n",
    "        # we store the size of our input coordinates and output values\n",
    "        self.coord_size = len(self.image.shape[:-1])  # Number of spatial dimensions\n",
    "        self.coords = torch.cartesian_prod(*list(torch.arange(0, d) for d in self.dim_sizes)).to(self.device)\n",
    "        self.value_size = self.image.shape[-1]  # Channel size\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.coords.shape[0]\n",
    "\n",
    "    def __getitem__(self, idx: int):\n",
    "        # Create random sample of pixel indices\n",
    "        point_indices = self.coords[idx]\n",
    "        # Retrieve image values from selected indices\n",
    "        point_values = self.image[tuple(point_indices)]\n",
    "\n",
    "        # Convert point indices into normalized [-1.0, 1.0] coordinates\n",
    "        point_coords = self.coords[idx]\n",
    "        spatial_dims = torch.tensor(self.dim_sizes, device=self.device)\n",
    "        point_coords_norm = point_coords / (spatial_dims / 2) - 1\n",
    "        # The subject index is also returned in case the user wants to use subject-wise learned latents\n",
    "        return point_coords_norm, point_values\n",
    "\n",
    "dataset = RandomPointsDataset(gt_image, points_num=POINTS_PER_SAMPLE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "0fa43e17-1965-4487-8361-668098052758",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Tuple, List, Optional\n",
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# We will track visual results every few epochs and visualize them after training\n",
    "def plot_reconstructions(progress_ims: List[Tuple[int, torch.Tensor]], gt_im: torch.Tensor):\n",
    "    ncols = len(progress_ims) + 1\n",
    "    fig_width = 5\n",
    "    fig, axs = plt.subplots(ncols=ncols, figsize=(ncols*fig_width, fig_width))\n",
    "    # Plot all reconstructions images predicted by the model\n",
    "    for i, (epoch, im, metric) in enumerate(progress_ims):\n",
    "        im = im.cpu().numpy()\n",
    "        ax = axs[i]\n",
    "        ax.imshow(im[img.shape[0] // 2], cmap='gray')\n",
    "        ax.axis('off')\n",
    "        title = f'Epoch: {epoch}, PSNR: {metric}'\n",
    "        ax.set_title(title)\n",
    "    # PLot ground-truth image\n",
    "    gt_im = gt_im.cpu().numpy()\n",
    "    axs[-1].imshow(gt_im, cmap='gray')\n",
    "    axs[-1].axis('off')\n",
    "    axs[-1].set_title('Ground Truth')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# We will also track the PSNR of our training samples\n",
    "def psnr(pred, ref):\n",
    "    max_value = ref.max()\n",
    "    mse = torch.mean((pred - ref) ** 2, dim=(-2, -1))\n",
    "    out = 20 * torch.log10(max_value / torch.sqrt(mse))\n",
    "    return out.mean()\n",
    "\n",
    "# Let's create a function to plot our psnr scores throughout training\n",
    "def plot_scores(models: List['INRModule']):\n",
    "    fig, ax = plt.subplots()\n",
    "    # For each model, plot list of scores\n",
    "    for model in models:\n",
    "        epochs, scores = [i for i, _ in model.scores], [v for _, v in model.scores]\n",
    "        ax.plot(epochs, scores, label=model.name)\n",
    "    ax.set_xlabel('Epoch')\n",
    "    ax.set_ylabel('PSNR')\n",
    "    ax.set_title('PSNR over epochs')\n",
    "    ax.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "794d408a-b757-465c-a7d5-9cdeb4db7aaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "import lightning as pl\n",
    "\n",
    "class INRLightningModule(pl.LightningModule):\n",
    "    def __init__(self,\n",
    "                 network: MLP,\n",
    "                 gt_im: torch.Tensor,\n",
    "                 lr: float = 0.001,\n",
    "                 name: str = \"\",\n",
    "                 eval_interval: int = 100,\n",
    "                 visualization_intervals: List[int] = [0, 100, 500, 1000, 5000, 10000],\n",
    "                ):\n",
    "        super().__init__()\n",
    "        self.lr = lr\n",
    "        self.network = network\n",
    "\n",
    "        # Logging\n",
    "        self.name = name\n",
    "        self.gt_im = gt_im\n",
    "        self.eval_interval = eval_interval\n",
    "        self.visualization_intervals = visualization_intervals\n",
    "        self.progress_ims = []\n",
    "        self.scores = []\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.Adam(self.network.parameters(), lr=self.lr)\n",
    "\n",
    "    def forward(self, coords):\n",
    "        return self.network(coords)\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        coords, values = batch\n",
    "        coords = coords.view(-1, coords.shape[-1])\n",
    "        values = values.view(-1, values.shape[-1])\n",
    "        outputs = self.forward(coords.to(self.device))\n",
    "        loss = nn.functional.mse_loss(outputs, values.to(self.device))\n",
    "        return loss\n",
    "\n",
    "    def on_train_epoch_end(self):\n",
    "        \"\"\" At each visualization interval, reconstruct the image using our INR \"\"\"\n",
    "        if (self.current_epoch + 1) % self.eval_interval == 0 or self.current_epoch == 0:\n",
    "            pred_im = self.sample_at_resolution(self.gt_im.shape[:-1])\n",
    "            pred_im = pred_im.reshape(self.gt_im.shape)\n",
    "            psnr_value = psnr(pred_im, self.gt_im.to(pred_im.device)).cpu().item()\n",
    "            self.scores.append((self.current_epoch + 1, psnr_value))  # Log PSNR\n",
    "            if self.current_epoch + 1 in self.visualization_intervals:\n",
    "                self.progress_ims.append((self.current_epoch + 1, pred_im.cpu(), psnr_value))\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def sample_at_resolution(self, resolution: Tuple[int, ...]):\n",
    "        \"\"\" Evaluate our INR on a grid of coordinates in order to obtain an image. \"\"\"\n",
    "        meshgrid = torch.meshgrid([torch.arange(0, i, device=self.device) for i in resolution], indexing='ij')\n",
    "        coords = torch.stack(meshgrid, dim=-1)\n",
    "        coords_norm = coords / torch.tensor(resolution, device=self.device) * 2 - 1\n",
    "        coords_norm_ = coords_norm.reshape(-1, coords.shape[-1])\n",
    "        predictions = []\n",
    "        batch_size = 10000\n",
    "        print(coords_norm_.shape)\n",
    "        for i in tqdm(range(0, coords_norm_.shape[0], batch_size)):\n",
    "            predictions_ = self.forward(coords_norm_[i * batch_size:(i * batch_size) + batch_size])\n",
    "            print(predictions)\n",
    "            predictions.append(predictions_)\n",
    "        predictions_ = torch.stack(predictions)\n",
    "        predictions = predictions_.reshape(resolution)\n",
    "        return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "132d4881-3104-41dc-9285-694c017b3477",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's initialize our network\n",
    "HIDDEN_SIZE = 128\n",
    "NUM_LAYERS = 3\n",
    "\n",
    "inr = MLP(dataset.coord_size,\n",
    "          dataset.value_size,\n",
    "          hidden_size=HIDDEN_SIZE,\n",
    "          num_layers=NUM_LAYERS,\n",
    "          layer_class=ReLULayer, \n",
    "         ).to('cuda:0')\n",
    "\n",
    "dataloader = DataLoader(dataset, batch_size=2**15, num_workers=20, pin_memory=True, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4da8c433-b3ab-4c39-bf3a-d6327f32acc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name    | Type | Params | Mode \n",
      "-----------------------------------------\n",
      "0 | network | MLP  | 33.7 K | train\n",
      "-----------------------------------------\n",
      "33.7 K    Trainable params\n",
      "0         Non-trainable params\n",
      "33.7 K    Total params\n",
      "0.135     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b946af32582c45f3a25d2cb81c92689d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |                                                  | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7d2d73f5c8b0>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/thea1603/workspace/vitalab.github.io/.env/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1604, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/home/thea1603/workspace/vitalab.github.io/.env/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1587, in _shutdown_workers\n",
      "    if w.is_alive():\n",
      "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "AssertionError: can only test a child process\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7d2d73f5c8b0>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/thea1603/workspace/vitalab.github.io/.env/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1604, in __del__\n",
      "    self._shutdown_workers()\n",
      "Exception ignored in:   File \"/home/thea1603/workspace/vitalab.github.io/.env/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1587, in _shutdown_workers\n",
      "<function _MultiProcessingDataLoaderIter.__del__ at 0x7d2d73f5c8b0>\n",
      "    if w.is_alive():\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
      "      File \"/home/thea1603/workspace/vitalab.github.io/.env/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1604, in __del__\n",
      "assert self._parent_pid == os.getpid(), 'can only test a child process'    self._shutdown_workers()\n",
      "\n",
      "AssertionError  File \"/home/thea1603/workspace/vitalab.github.io/.env/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1587, in _shutdown_workers\n",
      ":     can only test a child processif w.is_alive():\n",
      "\n",
      "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "Exception ignored in: AssertionError<function _MultiProcessingDataLoaderIter.__del__ at 0x7d2d73f5c8b0>: \n",
      "can only test a child processTraceback (most recent call last):\n",
      "\n",
      "  File \"/home/thea1603/workspace/vitalab.github.io/.env/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1604, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/home/thea1603/workspace/vitalab.github.io/.env/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1587, in _shutdown_workers\n",
      "    if w.is_alive():\n",
      "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "AssertionError: can only test a child processException ignored in: \n",
      "<function _MultiProcessingDataLoaderIter.__del__ at 0x7d2d73f5c8b0>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/thea1603/workspace/vitalab.github.io/.env/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1604, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/home/thea1603/workspace/vitalab.github.io/.env/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1587, in _shutdown_workers\n",
      "    if w.is_alive():\n",
      "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "AssertionError: can only test a child process\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7d2d73f5c8b0>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/thea1603/workspace/vitalab.github.io/.env/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1604, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/home/thea1603/workspace/vitalab.github.io/.env/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1587, in _shutdown_workers\n",
      "    if w.is_alive():\n",
      "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
      "Exception ignored in:     <function _MultiProcessingDataLoaderIter.__del__ at 0x7d2d73f5c8b0>assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "Exception ignored in: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/thea1603/workspace/vitalab.github.io/.env/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1604, in __del__\n",
      "<function _MultiProcessingDataLoaderIter.__del__ at 0x7d2d73f5c8b0>Exception ignored in: AssertionError\n",
      "    <function _MultiProcessingDataLoaderIter.__del__ at 0x7d2d73f5c8b0>: self._shutdown_workers()Traceback (most recent call last):\n",
      "\n",
      "can only test a child process  File \"/home/thea1603/workspace/vitalab.github.io/.env/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1604, in __del__\n",
      "\n",
      "Traceback (most recent call last):\n",
      "\n",
      "  File \"/home/thea1603/workspace/vitalab.github.io/.env/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1587, in _shutdown_workers\n",
      "      File \"/home/thea1603/workspace/vitalab.github.io/.env/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1604, in __del__\n",
      "    self._shutdown_workers()if w.is_alive():    \n",
      "Exception ignored in: self._shutdown_workers()\n",
      "  File \"/home/thea1603/workspace/vitalab.github.io/.env/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1587, in _shutdown_workers\n",
      "<function _MultiProcessingDataLoaderIter.__del__ at 0x7d2d73f5c8b0>  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
      "    \n",
      "    \n",
      "  File \"/home/thea1603/workspace/vitalab.github.io/.env/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1587, in _shutdown_workers\n",
      "if w.is_alive():Traceback (most recent call last):\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'if w.is_alive():\n",
      "  File \"/home/thea1603/workspace/vitalab.github.io/.env/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1604, in __del__\n",
      "\n",
      "\n",
      "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
      "AssertionError  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
      "    :     self._shutdown_workers()    can only test a child process\n",
      "assert self._parent_pid == os.getpid(), 'can only test a child process'assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "\n",
      "AssertionError\n",
      ":   File \"/home/thea1603/workspace/vitalab.github.io/.env/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1587, in _shutdown_workers\n",
      "AssertionErrorcan only test a child process    \n",
      ": if w.is_alive():can only test a child process\n",
      "\n",
      "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "AssertionError: can only test a child processException ignored in: \n",
      "<function _MultiProcessingDataLoaderIter.__del__ at 0x7d2d73f5c8b0>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/thea1603/workspace/vitalab.github.io/.env/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1604, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/home/thea1603/workspace/vitalab.github.io/.env/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1587, in _shutdown_workers\n",
      "    if w.is_alive():\n",
      "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "AssertionError: can only test a child process\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7d2d73f5c8b0>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/thea1603/workspace/vitalab.github.io/.env/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1604, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/home/thea1603/workspace/vitalab.github.io/.env/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1587, in _shutdown_workers\n",
      "    if w.is_alive():\n",
      "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "AssertionError: can only test a child process\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7d2d73f5c8b0>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/thea1603/workspace/vitalab.github.io/.env/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1604, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/home/thea1603/workspace/vitalab.github.io/.env/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1587, in _shutdown_workers\n",
      "    if w.is_alive():\n",
      "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "AssertionError: can only test a child process\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7d2d73f5c8b0>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/thea1603/workspace/vitalab.github.io/.env/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1604, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/home/thea1603/workspace/vitalab.github.io/.env/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1587, in _shutdown_workers\n",
      "    if w.is_alive():\n",
      "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "AssertionError: can only test a child process\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7d2d73f5c8b0>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/thea1603/workspace/vitalab.github.io/.env/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1604, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/home/thea1603/workspace/vitalab.github.io/.env/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1587, in _shutdown_workers\n",
      "    if w.is_alive():\n",
      "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "AssertionError: can only test a child process\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7d2d73f5c8b0>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/thea1603/workspace/vitalab.github.io/.env/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1604, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/home/thea1603/workspace/vitalab.github.io/.env/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1587, in _shutdown_workers\n",
      "    if w.is_alive():\n",
      "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
      "    Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7d2d73f5c8b0>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/thea1603/workspace/vitalab.github.io/.env/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1604, in __del__\n",
      "assert self._parent_pid == os.getpid(), 'can only test a child process'    \n",
      "self._shutdown_workers()AssertionError: \n",
      "can only test a child process  File \"/home/thea1603/workspace/vitalab.github.io/.env/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1587, in _shutdown_workers\n",
      "    \n",
      "if w.is_alive():\n",
      "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "AssertionError: can only test a child process\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7d2d73f5c8b0>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/thea1603/workspace/vitalab.github.io/.env/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1604, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/home/thea1603/workspace/vitalab.github.io/.env/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1587, in _shutdown_workers\n",
      "    if w.is_alive():\n",
      "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "AssertionError: can only test a child process\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7d2d73f5c8b0>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/thea1603/workspace/vitalab.github.io/.env/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1604, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/home/thea1603/workspace/vitalab.github.io/.env/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1587, in _shutdown_workers\n",
      "    if w.is_alive():\n",
      "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "AssertionError: can only test a child process\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7d2d73f5c8b0>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/thea1603/workspace/vitalab.github.io/.env/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1604, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/home/thea1603/workspace/vitalab.github.io/.env/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1587, in _shutdown_workers\n",
      "    if w.is_alive():\n",
      "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "AssertionError: can only test a child process\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "# Let's initialize our lightning module\n",
    "LEARNING_RATE = 1e-3\n",
    "TRAINING_EPOCHS = 10000\n",
    "\n",
    "inr_module = INRLightningModule(network=inr, \n",
    "                                lr=LEARNING_RATE,\n",
    "                                gt_im=gt_image,\n",
    "                                name='ReLU',\n",
    "                                eval_interval=100,\n",
    "                                visualization_intervals=[0, 100, 500, 1000, 5000, 10000])\n",
    "trainer = pl.Trainer(max_epochs=TRAINING_EPOCHS)\n",
    "s = datetime.now()\n",
    "trainer.fit(inr_module, train_dataloaders=dataloader)\n",
    "print(f\"Fitting time: {datetime.now()-s}s.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b589b4e-f38e-47c6-91c0-22a5ba55b791",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's visualize the reconstruction progress during training!\n",
    "plot_reconstructions(inr_module.progress_ims, gt_image)\n",
    "plot_scores([inr_module])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d1f7d14-732f-4f05-93c4-cc917b9080d4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
